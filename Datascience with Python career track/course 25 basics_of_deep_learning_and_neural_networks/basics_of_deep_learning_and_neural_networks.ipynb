{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "basics-of-deep-learning-and-neural-networks.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eig665RLIbdu",
        "colab_type": "text"
      },
      "source": [
        "# Basics of deep learning and neural networks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JBboQ2gRv70",
        "colab_type": "text"
      },
      "source": [
        "## Forward Prop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPYJEDWJafaQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kK9xUL2InRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_data= np.array([3, 5])\n",
        "weights= {'node_0': np.array([2, 4]), \n",
        "          'node_1': np.array([ 4, -5]),\n",
        "          'output': np.array([2, 7])}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FANcmX9IInOT",
        "colab_type": "code",
        "outputId": "15b53a39-adf0-490e-fbf3-1cb2c61fb6e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Calculate node 0 value: node_0_value\n",
        "node_0_value = (input_data*weights['node_0']).sum()\n",
        "\n",
        "# Calculate node 1 value: node_1_value\n",
        "node_1_value = (input_data*weights['node_1']).sum()\n",
        "\n",
        "# Put node values into array: hidden_layer_outputs\n",
        "hidden_layer_outputs = np.array([node_0_value, node_1_value])\n",
        "\n",
        "# Calculate output: output\n",
        "output = (hidden_layer_outputs*weights['output']).sum()\n",
        "\n",
        "# Print output\n",
        "print(output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-39\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pAztUxgXxyH",
        "colab_type": "text"
      },
      "source": [
        "## relu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xte_muYBImyL",
        "colab_type": "code",
        "outputId": "f1a187d2-7b59-46b5-e67c-564c1e5bf2e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def relu(input):\n",
        "    '''Define your relu activation function here'''\n",
        "    # Calculate the value for the output of the relu function: output\n",
        "    output = max(0, input)\n",
        "    \n",
        "    # Return the value just calculated\n",
        "    return(output)\n",
        "\n",
        "# Calculate node 0 value: node_0_output\n",
        "node_0_input = (input_data * weights['node_0']).sum()\n",
        "node_0_output = relu(node_0_input)\n",
        "\n",
        "# Calculate node 1 value: node_1_output\n",
        "node_1_input = (input_data * weights['node_1']).sum()\n",
        "node_1_output = relu(node_1_input)\n",
        "\n",
        "# Put node values into array: hidden_layer_outputs\n",
        "hidden_layer_outputs = np.array([node_0_output, node_1_output])\n",
        "\n",
        "# Calculate model output (do not apply relu)\n",
        "model_output = (hidden_layer_outputs * weights['output']).sum()\n",
        "\n",
        "# Print model output\n",
        "print(model_output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "52\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "up5tjVfhX2K2",
        "colab_type": "text"
      },
      "source": [
        "## multiple data point"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3MX8QehLkMl",
        "colab_type": "text"
      },
      "source": [
        "Define a function called predict_with_network() which will generate predictions for multiple data observations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVzZeSTNImvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_data=[np.array([3, 5]), np.array([ 1, -1]), np.array([0, 0]), np.array([8, 4])]\n",
        "weights={'node_0': np.array([2, 4]), \n",
        "         'node_1': np.array([ 4, -5]), \n",
        "         'output': np.array([2, 7])}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1a3dYsOLgEP",
        "colab_type": "code",
        "outputId": "ec6a5f7e-833f-44ec-c9da-ca3b3c48f26d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Define predict_with_network()\n",
        "def predict_with_network1(input_data_row, weights):\n",
        "\n",
        "    # Calculate node 0 value\n",
        "    node_0_input = (input_data_row * weights['node_0']).sum()\n",
        "    node_0_output = relu(node_0_input)\n",
        "\n",
        "    # Calculate node 1 value\n",
        "    node_1_input = (input_data_row * weights['node_1']).sum()\n",
        "    node_1_output = relu(node_1_input)\n",
        "\n",
        "    # Put node values into array: hidden_layer_outputs\n",
        "    hidden_layer_outputs = np.array([node_0_output, node_1_output])\n",
        "    \n",
        "    # Calculate model output\n",
        "    input_to_final_layer = (hidden_layer_outputs * weights['output']).sum()\n",
        "    model_output = relu(input_to_final_layer)                                  ##I thought we are not supposed to use relu in the final layer!?\n",
        "    \n",
        "    # Return model output\n",
        "    return (model_output)\n",
        "\n",
        "\n",
        "# Create empty list to store prediction results\n",
        "results = []\n",
        "for input_data_row in input_data:\n",
        "    # Append prediction to results\n",
        "    results.append(predict_with_network1(input_data_row, weights))\n",
        "\n",
        "# Print results\n",
        "print(results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[52, 63, 0, 148]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7DEa4PUO_07",
        "colab_type": "text"
      },
      "source": [
        "**DL**\n",
        "- DL is also called Representation learning cause it forms sophisticated representation of data, untill we can make predictions on them (e.g on images)\n",
        "- DL partially replaced feature engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLOcjDJXXu8I",
        "colab_type": "text"
      },
      "source": [
        "## 2 layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDOyVxlYQGqB",
        "colab_type": "text"
      },
      "source": [
        "In this exercise, you'll write code to do forward propagation for a neural network with **2 hidden layers**. Each hidden layer has two nodes. The input data has been preloaded as input_data. The nodes in the first hidden layer are called node_0_0 and node_0_1. Their weights are pre-loaded as weights['node_0_0'] and weights['node_0_1'] respectively.\n",
        "\n",
        "The nodes in the second hidden layer are called node_1_0 and node_1_1. Their weights are pre-loaded as weights['node_1_0'] and weights['node_1_1'] respectively.\n",
        "\n",
        "We then create a model output from the hidden nodes using weights pre-loaded as weights['output']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teON8wxUMuH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights = {'node_0_0': np.array([2, 4]),\n",
        "            'node_0_1': np.array([ 4, -5]),\n",
        "            'node_1_0': np.array([-1,  2]),\n",
        "            'node_1_1': np.array([1, 2]),\n",
        "            'output': np.array([2, 7])}\n",
        "input_data= np.array([3, 5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9zwCH6iMuFV",
        "colab_type": "code",
        "outputId": "1a8169f9-0217-4f8d-ba40-c9cf5bfddd7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def predict_with_network(input_data):\n",
        "    # Calculate node 0 in the first hidden layer\n",
        "    node_0_0_input = (input_data * weights['node_0_0']).sum()\n",
        "    node_0_0_output = relu(node_0_0_input)\n",
        "\n",
        "    # Calculate node 1 in the first hidden layer\n",
        "    node_0_1_input = (input_data * weights['node_0_1']).sum()\n",
        "    node_0_1_output = relu(node_0_1_input)\n",
        "\n",
        "    # Put node values into array: hidden_0_outputs\n",
        "    hidden_0_outputs = np.array([node_0_0_output, node_0_1_output])\n",
        "    \n",
        "    # Calculate node 0 in the second hidden layer\n",
        "    node_1_0_input = (hidden_0_outputs * weights['node_1_0']).sum()\n",
        "    node_1_0_output = relu(node_1_0_input)\n",
        "\n",
        "    # Calculate node 1 in the second hidden layer\n",
        "    node_1_1_input = (hidden_0_outputs * weights['node_1_1']).sum()\n",
        "    node_1_1_output = relu(node_1_1_input)\n",
        "\n",
        "    # Put node values into array: hidden_1_outputs\n",
        "    hidden_1_outputs = np.array([node_1_0_output, node_1_1_output])\n",
        "\n",
        "    # Calculate model output: model_output\n",
        "    model_output = (hidden_1_outputs * weights['output']).sum()\n",
        "    #Do not apply the relu() function to this output.\n",
        "    #Ekhon boltese :|\n",
        "    \n",
        "    # Return model_output\n",
        "    return(model_output)\n",
        "\n",
        "output = predict_with_network(input_data)\n",
        "print(output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "182\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5Ij5g5ASCqL",
        "colab_type": "text"
      },
      "source": [
        "**The last layers capture the most complex interactions.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnZWtNO1Ibbl",
        "colab_type": "text"
      },
      "source": [
        "# Optimizing a neural network with backward propagation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psMTBLODSmDl",
        "colab_type": "text"
      },
      "source": [
        "**Loss function** aggregates all the loss of each data point.\n",
        "\n",
        "**Gradient Descent**:\n",
        "1. start at a random point\n",
        "2. Untill you are somewhere flat(all other directions are uphill):\n",
        "  - find the slope\n",
        "  - take a step downhill"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xs68BNkMVxRP",
        "colab_type": "text"
      },
      "source": [
        "## Manually change a weight to get perfect loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyLDtgO_UxOU",
        "colab_type": "code",
        "outputId": "b6039327-2a74-4764-c649-b3fa11cc32e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# The data point you will make a prediction for\n",
        "input_data = np.array([0, 3])\n",
        "\n",
        "# Sample weights\n",
        "weights_0 = {'node_0': [2, 1],\n",
        "             'node_1': [1, 2],\n",
        "             'output': [1, 1]\n",
        "            }\n",
        "\n",
        "# The actual target value, used to calculate the error\n",
        "target_actual = 3\n",
        "\n",
        "# Make prediction using original weights\n",
        "model_output_0 = predict_with_network1(input_data, weights_0)\n",
        "\n",
        "# Calculate error: error_0\n",
        "error_0 = model_output_0 - target_actual\n",
        "\n",
        "# Create weights that cause the network to make perfect prediction (3): weights_1\n",
        "weights_1 = {'node_0': [2, 1],\n",
        "             'node_1': [1, 0],\n",
        "             'output': [1, 1]\n",
        "            }\n",
        "\n",
        "# Make prediction using new weights: model_output_1\n",
        "model_output_1 = predict_with_network1(input_data,weights_1)\n",
        "\n",
        "# Calculate error: error_1\n",
        "error_1 = target_actual - model_output_1\n",
        "\n",
        "# Print error_0 and error_1\n",
        "print(error_0)\n",
        "print(error_1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKW6fd-9WmiI",
        "colab_type": "text"
      },
      "source": [
        "## multiple data points"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNA5bzD7WmO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_actuals = [1, 3, 5, 7]\n",
        "\n",
        "weights_0={'node_0': np.array([2, 1]), \n",
        "           'node_1': np.array([1, 2]), \n",
        "           'output': np.array([1, 1])}\n",
        "\n",
        "weights_1={'node_0': np.array([2, 1]),\n",
        "            'node_1': np.array([1. , 1.5]),\n",
        "            'output': np.array([1. , 1.5])}\n",
        "\n",
        "input_data=[np.array([0, 3]), np.array([1, 2]), np.array([-1, -2]), np.array([4, 0])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtDFYmTkXJoa",
        "colab_type": "code",
        "outputId": "aa7b19c1-d951-4b33-a8de-e87e3c9bec39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Create model_output_0 \n",
        "model_output_0 = []\n",
        "# Create model_output_1\n",
        "model_output_1 = []\n",
        "\n",
        "# Loop over input_data\n",
        "for row in input_data:\n",
        "    # Append prediction to model_output_0\n",
        "    model_output_0.append(predict_with_network1(row,weights_0))\n",
        "    \n",
        "    # Append prediction to model_output_1\n",
        "    model_output_1.append(predict_with_network1(row,weights_1))\n",
        "\n",
        "# Calculate the mean squared error for model_output_0: mse_0\n",
        "mse_0 = mean_squared_error(target_actuals,model_output_0)\n",
        "\n",
        "# Calculate the mean squared error for model_output_1: mse_1\n",
        "mse_1 = mean_squared_error(target_actuals,model_output_1)\n",
        "\n",
        "# Print mse_0 and mse_1\n",
        "print(\"Mean squared error with weights_0: %f\" %mse_0)\n",
        "print(\"Mean squared error with weights_1: %f\" %mse_1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean squared error with weights_0: 37.500000\n",
            "Mean squared error with weights_1: 49.890625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4w7ttztQYpnk",
        "colab_type": "text"
      },
      "source": [
        "## slope\n",
        "- slope = slope of loss func wrt the value of the node we feed into (output node) * value of the node we feed into our weight (node before the output node) * slope of act func wrt output node\n",
        "- w_new = w - lr*(slope)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHPe7b1vZ-N9",
        "colab_type": "text"
      },
      "source": [
        "When plotting the mean-squared error loss function against predictions, the slope is 2 * x * (y-xb), or 2 * input_data * error. Note that x and b may have multiple numbers (x is a vector for each data point, and b is a vector). In this case, the output will also be a vector, which is exactly what you want."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHuNAv8kXJlT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target=0\n",
        "weights=np.array([0, 2, 1])\n",
        "input_data=np.array([1, 2, 3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8NDx9O4d3n5",
        "colab_type": "code",
        "outputId": "544c163b-9e0f-46e7-c84b-01f56fde3a07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Calculate the predictions: preds\n",
        "preds = (input_data*weights).sum()\n",
        "\n",
        "# Calculate the error: error\n",
        "error = target - preds\n",
        "\n",
        "# Calculate the slope: slope\n",
        "slope = 2 * input_data * error\n",
        "\n",
        "# Print the slope\n",
        "print(slope)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-14 -28 -42]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRwGjhoJd3la",
        "colab_type": "code",
        "outputId": "e6e87f94-3012-470b-ad21-5c567def3223",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Set the learning rate: learning_rate\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Calculate the predictions: preds\n",
        "preds = (weights * input_data).sum()\n",
        "\n",
        "# Calculate the error: error\n",
        "error = preds - target\n",
        "\n",
        "# Calculate the slope: slope\n",
        "slope = 2 * input_data * error\n",
        "\n",
        "# Update the weights: weights_updated\n",
        "weights_updated = weights - learning_rate*slope\n",
        "\n",
        "# Get updated predictions: preds_updated\n",
        "preds_updated = (weights_updated * input_data).sum()\n",
        "\n",
        "# Calculate updated error: error_updated\n",
        "error_updated = preds_updated - target\n",
        "\n",
        "# Print the original error\n",
        "print(error)\n",
        "\n",
        "# Print the updated error\n",
        "print(error_updated)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n",
            "5.04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxrsAx3YfAch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_slope(input_data, target, weights):\n",
        "  preds = (weights * input_data).sum()\n",
        "  error = preds - target\n",
        "  slope = 2 * input_data * error\n",
        "  return slope\n",
        "\n",
        "def get_mse(input_data, target, weights):\n",
        "  preds = (weights * input_data).sum()\n",
        "  return (preds-target)**2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_ODVr6AgOa7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mSLSU5-egxCP",
        "colab": {}
      },
      "source": [
        "target=0\n",
        "weights=np.array([0, 2, 1])\n",
        "input_data=np.array([1, 2, 3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apGiOb28d3h7",
        "colab_type": "code",
        "outputId": "9ab5cbcb-6af7-4578-9ed6-8a1a5fcf4910",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "n_updates = 20\n",
        "mse_hist = []\n",
        "\n",
        "# Iterate over the number of updates\n",
        "for i in range(n_updates):\n",
        "    # Calculate the slope: slope\n",
        "    slope = get_slope(input_data, target, weights)\n",
        "    \n",
        "    # Update the weights: weights\n",
        "    weights = weights - 0.01 * slope\n",
        "    \n",
        "    # Calculate mse with new weights: mse\n",
        "    mse = get_mse(input_data, target, weights)\n",
        "    \n",
        "    # Append the mse to mse_hist\n",
        "    mse_hist.append(mse)\n",
        "\n",
        "# Plot the mse history\n",
        "plt.plot(mse_hist)\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Mean Squared Error')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAhGRmFMiEBGJOSUCEZGY+/9G8e4pUnWtswAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-P7IB6YhRKp",
        "colab_type": "text"
      },
      "source": [
        "## Back prop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYEZtGLChTPE",
        "colab_type": "text"
      },
      "source": [
        "Gradient for weight is product of:\n",
        "- node value feeding into that weight\n",
        "- slope of loss func wrt node it feeds into\n",
        "- slope of activation function at the mode it feeds into"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Qfc1w_vIbaW",
        "colab_type": "text"
      },
      "source": [
        "# Building deep learning models with keras\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueCEbRmXpk26",
        "colab_type": "text"
      },
      "source": [
        " For convenience, everything in df except for the target has been converted to a NumPy matrix called predictors. The target, wage_per_hour, is available as a NumPy matrix called target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iatEb2o-px0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROn9A1ZwcmEW",
        "colab_type": "text"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58eK0wVoplp4",
        "colab_type": "code",
        "outputId": "83e8fb8c-689d-4926-e8d4-de31ae683944",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "hr = 'https://assets.datacamp.com/production/repositories/654/datasets/8a57adcdb5bfb3e603dad7d3c61682dfe63082b8/hourly_wages.csv'\n",
        "hr = pd.read_csv(hr)\n",
        "hr.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wage_per_hour</th>\n",
              "      <th>union</th>\n",
              "      <th>education_yrs</th>\n",
              "      <th>experience_yrs</th>\n",
              "      <th>age</th>\n",
              "      <th>female</th>\n",
              "      <th>marr</th>\n",
              "      <th>south</th>\n",
              "      <th>manufacturing</th>\n",
              "      <th>construction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.10</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>21</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.95</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>42</td>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.67</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.00</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.50</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>17</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   wage_per_hour  union  education_yrs  ...  south  manufacturing  construction\n",
              "0           5.10      0              8  ...      0              1             0\n",
              "1           4.95      0              9  ...      0              1             0\n",
              "2           6.67      0             12  ...      0              1             0\n",
              "3           4.00      0             12  ...      0              0             0\n",
              "4           7.50      0             12  ...      0              0             0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwicAz5Nplns",
        "colab_type": "code",
        "outputId": "fda68358-e886-4e6b-a5d0-a84094d24577",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "mnist = 'https://assets.datacamp.com/production/repositories/654/datasets/24769dae9dc51a77b9baa785d42ea42e3f8f7538/mnist.csv'\n",
        "mnist = pd.read_csv(mnist,header=None)\n",
        "mnist.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "      <th>769</th>\n",
              "      <th>770</th>\n",
              "      <th>771</th>\n",
              "      <th>772</th>\n",
              "      <th>773</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "      <th>784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.38</td>\n",
              "      <td>...</td>\n",
              "      <td>0.578</td>\n",
              "      <td>0.579</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.581</td>\n",
              "      <td>0.582</td>\n",
              "      <td>0.583</td>\n",
              "      <td>0.584</td>\n",
              "      <td>0.585</td>\n",
              "      <td>0.586</td>\n",
              "      <td>0.587</td>\n",
              "      <td>0.588</td>\n",
              "      <td>0.589</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.591</td>\n",
              "      <td>0.592</td>\n",
              "      <td>0.593</td>\n",
              "      <td>0.594</td>\n",
              "      <td>0.595</td>\n",
              "      <td>0.596</td>\n",
              "      <td>0.597</td>\n",
              "      <td>0.598</td>\n",
              "      <td>0.599</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.601</td>\n",
              "      <td>0.602</td>\n",
              "      <td>0.603</td>\n",
              "      <td>0.604</td>\n",
              "      <td>0.605</td>\n",
              "      <td>0.606</td>\n",
              "      <td>0.607</td>\n",
              "      <td>0.608</td>\n",
              "      <td>0.609</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.611</td>\n",
              "      <td>0.612</td>\n",
              "      <td>0.613</td>\n",
              "      <td>0.614</td>\n",
              "      <td>0.615</td>\n",
              "      <td>0.616</td>\n",
              "      <td>0.617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0    1    2    3    4    5    ...    779    780    781    782    783    784\n",
              "0    5    0  0.1  0.2  0.3  0.4  ...  0.612  0.613  0.614  0.615  0.616  0.617\n",
              "1    4    0  0.0  0.0  0.0  0.0  ...  0.000  0.000  0.000  0.000  0.000  0.000\n",
              "2    3    0  0.0  0.0  0.0  0.0  ...  0.000  0.000  0.000  0.000  0.000  0.000\n",
              "3    0    0  0.0  0.0  0.0  0.0  ...  0.000  0.000  0.000  0.000  0.000  0.000\n",
              "4    2    0  0.0  0.0  0.0  0.0  ...  0.000  0.000  0.000  0.000  0.000  0.000\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzMD71r0plfR",
        "colab_type": "code",
        "outputId": "5085eb0d-2dc3-4143-a5fe-dcd227f00969",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "titanic = 'https://assets.datacamp.com/production/repositories/654/datasets/92b75b9bc0c0a8a30999d76f4a1ee786ef072a9c/titanic_all_numeric.csv'\n",
        "titanic = pd.read_csv(titanic)\n",
        "titanic.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>pclass</th>\n",
              "      <th>age</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>male</th>\n",
              "      <th>age_was_missing</th>\n",
              "      <th>embarked_from_cherbourg</th>\n",
              "      <th>embarked_from_queenstown</th>\n",
              "      <th>embarked_from_southampton</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   survived  pclass  ...  embarked_from_queenstown  embarked_from_southampton\n",
              "0         0       3  ...                         0                          1\n",
              "1         1       1  ...                         0                          0\n",
              "2         1       3  ...                         0                          1\n",
              "3         1       1  ...                         0                          1\n",
              "4         0       3  ...                         0                          1\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J9Xqd6RcpEu",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ouw0Q2Mylht0",
        "colab_type": "text"
      },
      "source": [
        "### Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaAgUZGUgmhI",
        "colab_type": "code",
        "outputId": "f5015e5e-a3ca-4157-c1d2-dfca3876629b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y = hr.loc[:,'wage_per_hour'].values\n",
        "X = hr.iloc[:,1:].values\n",
        "y.shape, X.shape, hr.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((534,), (534, 9), (534, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gnre9Q29hiSz",
        "colab_type": "text"
      },
      "source": [
        "- Scalinf before fitting can ease optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3iLUydwcrKI",
        "colab_type": "code",
        "outputId": "164a9ad1-09dd-4106-f3fb-4eecf5304c0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "\n",
        "# Import necessary modules\n",
        "import keras\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "\n",
        "# Specify the model\n",
        "n_cols = X.shape[1]\n",
        "model = Sequential()\n",
        "model.add(Dense(50, activation='relu', input_shape = (n_cols,)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X,y,epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "534/534 [==============================] - 0s 683us/step - loss: 281.8101\n",
            "Epoch 2/10\n",
            "534/534 [==============================] - 0s 71us/step - loss: 41.5805\n",
            "Epoch 3/10\n",
            "534/534 [==============================] - 0s 75us/step - loss: 25.5466\n",
            "Epoch 4/10\n",
            "534/534 [==============================] - 0s 58us/step - loss: 23.7893\n",
            "Epoch 5/10\n",
            "534/534 [==============================] - 0s 50us/step - loss: 23.1255\n",
            "Epoch 6/10\n",
            "534/534 [==============================] - 0s 50us/step - loss: 22.8580\n",
            "Epoch 7/10\n",
            "534/534 [==============================] - 0s 51us/step - loss: 22.5708\n",
            "Epoch 8/10\n",
            "534/534 [==============================] - 0s 55us/step - loss: 22.3361\n",
            "Epoch 9/10\n",
            "534/534 [==============================] - 0s 52us/step - loss: 22.1579\n",
            "Epoch 10/10\n",
            "534/534 [==============================] - 0s 52us/step - loss: 22.1677\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7feac422bef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC_rq3dQkFR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "?model.fit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hgl9k6Bljur",
        "colab_type": "text"
      },
      "source": [
        "### Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X88XgRztllwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictors = titanic.drop('survived',axis=1).values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9KxF2P-lfi8",
        "colab_type": "code",
        "outputId": "37e0806a-7023-464e-f868-9917d75c0c19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# Import necessary modules\n",
        "import keras\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Convert the target to categorical: target\n",
        "target = to_categorical(titanic.survived)\n",
        "n_cols = predictors.shape[1]\n",
        "# Set up the model\n",
        "model = Sequential()\n",
        "\n",
        "# Add the first layer\n",
        "model.add(Dense(32, activation='relu', input_shape = (n_cols,)))\n",
        "\n",
        "# Add the output layer\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(predictors,target,epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "891/891 [==============================] - 0s 398us/step - loss: 3.3883 - acc: 0.5825\n",
            "Epoch 2/10\n",
            "891/891 [==============================] - 0s 52us/step - loss: 1.6857 - acc: 0.6094\n",
            "Epoch 3/10\n",
            "891/891 [==============================] - 0s 52us/step - loss: 0.9922 - acc: 0.6162\n",
            "Epoch 4/10\n",
            "891/891 [==============================] - 0s 49us/step - loss: 0.6593 - acc: 0.6700\n",
            "Epoch 5/10\n",
            "891/891 [==============================] - 0s 49us/step - loss: 0.6097 - acc: 0.6824\n",
            "Epoch 6/10\n",
            "891/891 [==============================] - 0s 49us/step - loss: 0.6313 - acc: 0.6790\n",
            "Epoch 7/10\n",
            "891/891 [==============================] - 0s 44us/step - loss: 0.6107 - acc: 0.6801\n",
            "Epoch 8/10\n",
            "891/891 [==============================] - 0s 47us/step - loss: 0.6045 - acc: 0.7003\n",
            "Epoch 9/10\n",
            "891/891 [==============================] - 0s 51us/step - loss: 0.5890 - acc: 0.6958\n",
            "Epoch 10/10\n",
            "891/891 [==============================] - 0s 59us/step - loss: 0.5837 - acc: 0.6880\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7feac3c3ac88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JdEHZoGm64v",
        "colab_type": "code",
        "outputId": "78f66273-e521-473b-acb1-59a869953d34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "model.save('model.h5')\n",
        "new_model=load_model('model.h5')\n",
        "new_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_20 (Dense)             (None, 32)                352       \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 418\n",
            "Trainable params: 418\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J25miGnBm5Ly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate predictions: predictions\n",
        "predictions = model.predict(predictors)\n",
        "\n",
        "# Calculate predicted probability of survival: predicted_prob_true\n",
        "predicted_prob_true = predictions[:,1]>=0.8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apTvRHGynoro",
        "colab_type": "code",
        "outputId": "4fa7dabf-bc1f-4d05-f031-1f00bf1cb394",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Calculate predictions: predictions\n",
        "predictions = new_model.predict(predictors)\n",
        "\n",
        "# Calculate predicted probability of survival: predicted_prob_true\n",
        "new_predicted_prob_true = predictions[:,1]>=0.8\n",
        "\n",
        "(new_predicted_prob_true!=predicted_prob_true).sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvz8KkLxIbWY",
        "colab_type": "text"
      },
      "source": [
        "# Fine-tuning keras models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZlnrFW5oX1V",
        "colab_type": "text"
      },
      "source": [
        "- test various learning rates with a simpler optimizer such as sgd\n",
        "- there may be dying neuron problem, where if a node starts getting negative input, in case of relu, its slope will also be zero, and it wont get updated, and will remain zero. Thus contributing nothing to the model.\n",
        "- vanishing gradient problem: when the slope is too small, overtime  the updates are close to zero. eg. the higher and lower values of a tanh activation have very flat slope."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE0NVT_ArGCD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(32, activation='relu', input_shape = (n_cols,)))\n",
        "  model.add(Dense(2, activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlUUSzbgodrb",
        "colab_type": "code",
        "outputId": "3f06837f-ef93-41e0-f8e8-73424358628e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "# Import the SGD optimizer\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "# Create list of learning rates: lr_to_test\n",
        "lr_to_test = [.000001,0.01,1]\n",
        "\n",
        "# Loop over learning rates\n",
        "for lr in lr_to_test:\n",
        "    print('\\n\\nTesting model with learning rate: %f\\n'%lr )\n",
        "    \n",
        "    # Build new model to test, unaffected by previous models\n",
        "    model = get_model()\n",
        "    \n",
        "    # Create SGD optimizer with specified learning rate: my_optimizer\n",
        "    my_optimizer = SGD(lr=lr)\n",
        "    \n",
        "    # Compile the model\n",
        "    model.compile(optimizer=my_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    # Fit the model\n",
        "    model.fit(predictors,target,epochs=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Testing model with learning rate: 0.000001\n",
            "\n",
            "Epoch 1/5\n",
            "891/891 [==============================] - 1s 740us/step - loss: 2.1493 - acc: 0.6734\n",
            "Epoch 2/5\n",
            "891/891 [==============================] - 0s 51us/step - loss: 2.1458 - acc: 0.6734\n",
            "Epoch 3/5\n",
            "891/891 [==============================] - 0s 45us/step - loss: 2.1423 - acc: 0.6734\n",
            "Epoch 4/5\n",
            "891/891 [==============================] - 0s 48us/step - loss: 2.1388 - acc: 0.6734\n",
            "Epoch 5/5\n",
            "891/891 [==============================] - 0s 43us/step - loss: 2.1353 - acc: 0.6734\n",
            "\n",
            "\n",
            "Testing model with learning rate: 0.010000\n",
            "\n",
            "Epoch 1/5\n",
            "891/891 [==============================] - 1s 792us/step - loss: 2.6673 - acc: 0.5825\n",
            "Epoch 2/5\n",
            "891/891 [==============================] - 0s 49us/step - loss: 1.2339 - acc: 0.6274\n",
            "Epoch 3/5\n",
            "891/891 [==============================] - 0s 48us/step - loss: 1.0191 - acc: 0.6195\n",
            "Epoch 4/5\n",
            "891/891 [==============================] - 0s 51us/step - loss: 0.7599 - acc: 0.6431\n",
            "Epoch 5/5\n",
            "891/891 [==============================] - 0s 45us/step - loss: 0.7273 - acc: 0.6689\n",
            "\n",
            "\n",
            "Testing model with learning rate: 1.000000\n",
            "\n",
            "Epoch 1/5\n",
            "891/891 [==============================] - 1s 872us/step - loss: 9.8024 - acc: 0.3906\n",
            "Epoch 2/5\n",
            "891/891 [==============================] - 0s 43us/step - loss: 9.9314 - acc: 0.3838\n",
            "Epoch 3/5\n",
            "891/891 [==============================] - 0s 44us/step - loss: 9.9314 - acc: 0.3838\n",
            "Epoch 4/5\n",
            "891/891 [==============================] - 0s 46us/step - loss: 9.9314 - acc: 0.3838\n",
            "Epoch 5/5\n",
            "891/891 [==============================] - 0s 44us/step - loss: 9.9314 - acc: 0.3838\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8orA_9rlsDeV",
        "colab_type": "text"
      },
      "source": [
        "## model validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gloMWbqsFNJ",
        "colab_type": "text"
      },
      "source": [
        "- deep learning is typically used on large datasets\n",
        "- so usually we use validation split, instead of k-fold cross validation because:\n",
        "  - the validation data is large enough, so we can trust this score\n",
        "  - cross-valdation is expensive\n",
        "- include, validation_split=0.3 in .fit method\n",
        "- we introduce early stopping, with a parameter patience. It means how many epochs the model can go without improving.2/3 is good. Add it in a list to .fit under the parameter callbacks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIbJv-ZGt65d",
        "colab_type": "text"
      },
      "source": [
        "### validation split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I9Di5YRrWNV",
        "colab_type": "code",
        "outputId": "9b20121f-6d18-4a87-8d4c-be17a4102b1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# Save the number of columns in predictors: n_cols\n",
        "n_cols = predictors.shape[1]\n",
        "input_shape = (n_cols,)\n",
        "\n",
        "# Specify the model\n",
        "model = Sequential()\n",
        "model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "hist = model.fit(predictors,target,validation_split=0.3,epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 623 samples, validate on 268 samples\n",
            "Epoch 1/10\n",
            "623/623 [==============================] - 1s 2ms/step - loss: 1.0845 - acc: 0.5939 - val_loss: 0.6530 - val_acc: 0.7201\n",
            "Epoch 2/10\n",
            "623/623 [==============================] - 0s 92us/step - loss: 0.6389 - acc: 0.6677 - val_loss: 0.5226 - val_acc: 0.7313\n",
            "Epoch 3/10\n",
            "623/623 [==============================] - 0s 75us/step - loss: 0.5956 - acc: 0.6661 - val_loss: 0.5696 - val_acc: 0.7201\n",
            "Epoch 4/10\n",
            "623/623 [==============================] - 0s 69us/step - loss: 0.5875 - acc: 0.6950 - val_loss: 0.5105 - val_acc: 0.7239\n",
            "Epoch 5/10\n",
            "623/623 [==============================] - 0s 77us/step - loss: 0.6037 - acc: 0.6790 - val_loss: 0.5382 - val_acc: 0.7425\n",
            "Epoch 6/10\n",
            "623/623 [==============================] - 0s 71us/step - loss: 0.6306 - acc: 0.6902 - val_loss: 0.5553 - val_acc: 0.7500\n",
            "Epoch 7/10\n",
            "623/623 [==============================] - 0s 74us/step - loss: 0.5684 - acc: 0.7063 - val_loss: 0.4874 - val_acc: 0.7724\n",
            "Epoch 8/10\n",
            "623/623 [==============================] - 0s 67us/step - loss: 0.6016 - acc: 0.6870 - val_loss: 0.5607 - val_acc: 0.7127\n",
            "Epoch 9/10\n",
            "623/623 [==============================] - 0s 70us/step - loss: 0.6005 - acc: 0.7030 - val_loss: 0.4805 - val_acc: 0.7649\n",
            "Epoch 10/10\n",
            "623/623 [==============================] - 0s 68us/step - loss: 0.5653 - acc: 0.7319 - val_loss: 0.5610 - val_acc: 0.7575\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yad-348ft9Gj",
        "colab_type": "code",
        "outputId": "058d67b6-979c-4d2e-b55f-698a921ebbac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# Import EarlyStopping\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Save the number of columns in predictors: n_cols\n",
        "n_cols = predictors.shape[1]\n",
        "input_shape = (n_cols,)\n",
        "\n",
        "# Specify the model\n",
        "model = Sequential()\n",
        "model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define early_stopping_monitor\n",
        "early_stopping_monitor = EarlyStopping(patience=2)\n",
        "\n",
        "# Fit the model\n",
        "hist = model.fit(predictors,target,validation_split=0.3,epochs=30,callbacks=[early_stopping_monitor])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 623 samples, validate on 268 samples\n",
            "Epoch 1/30\n",
            "623/623 [==============================] - 1s 2ms/step - loss: 0.8031 - acc: 0.6437 - val_loss: 0.5770 - val_acc: 0.7164\n",
            "Epoch 2/30\n",
            "623/623 [==============================] - 0s 76us/step - loss: 0.7432 - acc: 0.6340 - val_loss: 0.6288 - val_acc: 0.6903\n",
            "Epoch 3/30\n",
            "623/623 [==============================] - 0s 74us/step - loss: 0.6971 - acc: 0.6388 - val_loss: 0.5758 - val_acc: 0.7052\n",
            "Epoch 4/30\n",
            "623/623 [==============================] - 0s 75us/step - loss: 0.6182 - acc: 0.6709 - val_loss: 0.5436 - val_acc: 0.7761\n",
            "Epoch 5/30\n",
            "623/623 [==============================] - 0s 79us/step - loss: 0.5964 - acc: 0.7127 - val_loss: 0.4970 - val_acc: 0.7836\n",
            "Epoch 6/30\n",
            "623/623 [==============================] - 0s 78us/step - loss: 0.5723 - acc: 0.7063 - val_loss: 0.5235 - val_acc: 0.7201\n",
            "Epoch 7/30\n",
            "623/623 [==============================] - 0s 86us/step - loss: 0.6197 - acc: 0.6966 - val_loss: 0.6285 - val_acc: 0.7239\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TH9bOZsAvMQ6",
        "colab_type": "text"
      },
      "source": [
        "**Stopped on just 7 epochs**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGatYBMNwDLi",
        "colab_type": "text"
      },
      "source": [
        "## testing various node number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rQ2arqrvKsp",
        "colab_type": "code",
        "outputId": "8e7400a7-f113-48e2-af68-7701222e7d86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "model_1 = Sequential()\n",
        "model_1.add(Dense(10, activation='relu', input_shape = input_shape))\n",
        "model_1.add(Dense(10, activation='relu'))\n",
        "model_1.add(Dense(2, activation='softmax'))\n",
        "model_1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define early_stopping_monitor\n",
        "early_stopping_monitor = EarlyStopping(patience=2)\n",
        "\n",
        "# Create the new model: model_2\n",
        "model_2 = Sequential()\n",
        "model_2.add(Dense(100, activation='relu', input_shape = input_shape))\n",
        "model_2.add(Dense(100, activation='relu'))\n",
        "model_2.add(Dense(2, activation='softmax'))\n",
        "# Compile model_2\n",
        "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit model_1\n",
        "model_1_training = model_1.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n",
        "\n",
        "# Fit model_2\n",
        "model_2_training = model_2.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n",
        "\n",
        "# Create the plot\n",
        "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation score')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngoiI1FJSEBGRWkoKIiJSS0lBRERq/T96o43To0zP2gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHKyh74VwswA",
        "colab_type": "text"
      },
      "source": [
        "## test with various number of layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Cy1URhdwN-N",
        "colab_type": "code",
        "outputId": "343041b8-29a5-4076-e854-2584c646d189",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "# The input shape to use in the first hidden layer\n",
        "input_shape = (n_cols,)\n",
        "\n",
        "##model-1\n",
        "model_1 = Sequential()\n",
        "model_1.add(Dense(50, activation='relu', input_shape = input_shape))\n",
        "model_1.add(Dense(2, activation='softmax'))\n",
        "# Compile model_2\n",
        "model_1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Create the new model: model_2\n",
        "model_2 = Sequential()\n",
        "model_2.add(Dense(50, activation='relu', input_shape = input_shape))\n",
        "model_2.add(Dense(50, activation='relu'))\n",
        "model_2.add(Dense(50, activation='relu'))\n",
        "model_2.add(Dense(2, activation='softmax'))\n",
        "# Compile model_2\n",
        "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit model 1\n",
        "model_1_training = model_1.fit(predictors, target, epochs=20, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=False)\n",
        "\n",
        "# Fit model 2\n",
        "model_2_training = model_2.fit(predictors, target, epochs=20, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=False)\n",
        "\n",
        "# Create the plot\n",
        "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation score')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nC+ecc3H9PzZA7RyUF9jZAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBs1R6bDxXyA",
        "colab_type": "text"
      },
      "source": [
        "**Deciding what models to try**\n",
        "- is still an art\n",
        "- but we should take into consideration the model capacity\n",
        "\n",
        "**General Rule**\n",
        "- start with a simple model\n",
        "- if score gets better keep incresing capacity(node/layer or #of layers)\n",
        "- else reduce capacity\n",
        "\n",
        "**Howards method**\n",
        "- build an unnecessarily large model\n",
        "- if it overfits, keep adding regularization and dropouts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3sQciunza7U",
        "colab_type": "text"
      },
      "source": [
        "https://www.datacamp.com/community/tutorials/deep-learning-jupyter-aws"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aXpScdizdva",
        "colab_type": "text"
      },
      "source": [
        "## Image classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZ0SLdKHxPkC",
        "colab_type": "code",
        "outputId": "91b62755-4f7f-44fa-cac9-513f41be1e12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "mnist.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "      <th>768</th>\n",
              "      <th>769</th>\n",
              "      <th>770</th>\n",
              "      <th>771</th>\n",
              "      <th>772</th>\n",
              "      <th>773</th>\n",
              "      <th>774</th>\n",
              "      <th>775</th>\n",
              "      <th>776</th>\n",
              "      <th>777</th>\n",
              "      <th>778</th>\n",
              "      <th>779</th>\n",
              "      <th>780</th>\n",
              "      <th>781</th>\n",
              "      <th>782</th>\n",
              "      <th>783</th>\n",
              "      <th>784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.38</td>\n",
              "      <td>...</td>\n",
              "      <td>0.578</td>\n",
              "      <td>0.579</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.581</td>\n",
              "      <td>0.582</td>\n",
              "      <td>0.583</td>\n",
              "      <td>0.584</td>\n",
              "      <td>0.585</td>\n",
              "      <td>0.586</td>\n",
              "      <td>0.587</td>\n",
              "      <td>0.588</td>\n",
              "      <td>0.589</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.591</td>\n",
              "      <td>0.592</td>\n",
              "      <td>0.593</td>\n",
              "      <td>0.594</td>\n",
              "      <td>0.595</td>\n",
              "      <td>0.596</td>\n",
              "      <td>0.597</td>\n",
              "      <td>0.598</td>\n",
              "      <td>0.599</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.601</td>\n",
              "      <td>0.602</td>\n",
              "      <td>0.603</td>\n",
              "      <td>0.604</td>\n",
              "      <td>0.605</td>\n",
              "      <td>0.606</td>\n",
              "      <td>0.607</td>\n",
              "      <td>0.608</td>\n",
              "      <td>0.609</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.611</td>\n",
              "      <td>0.612</td>\n",
              "      <td>0.613</td>\n",
              "      <td>0.614</td>\n",
              "      <td>0.615</td>\n",
              "      <td>0.616</td>\n",
              "      <td>0.617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0    1    2    3    4    5    ...    779    780    781    782    783    784\n",
              "0    5    0  0.1  0.2  0.3  0.4  ...  0.612  0.613  0.614  0.615  0.616  0.617\n",
              "1    4    0  0.0  0.0  0.0  0.0  ...  0.000  0.000  0.000  0.000  0.000  0.000\n",
              "2    3    0  0.0  0.0  0.0  0.0  ...  0.000  0.000  0.000  0.000  0.000  0.000\n",
              "3    0    0  0.0  0.0  0.0  0.0  ...  0.000  0.000  0.000  0.000  0.000  0.000\n",
              "4    2    0  0.0  0.0  0.0  0.0  ...  0.000  0.000  0.000  0.000  0.000  0.000\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-KdIzPxzkb1",
        "colab_type": "code",
        "outputId": "4b5bb7cf-7cbd-47a1-b111-e534518d5c9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mnist.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2001, 785)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbD_5PGQz4az",
        "colab_type": "code",
        "outputId": "cd712da7-6797-4cbd-e21c-02abe13d7548",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.sqrt(784)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxm8hT_G0fvm",
        "colab_type": "code",
        "outputId": "772be354-004d-40ae-fa39-e5f11b616774",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mnist.iloc[0,1:].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTBaiLZazliU",
        "colab_type": "code",
        "outputId": "cb943026-1cba-4cfa-b327-434df8f7cc23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(mnist.iloc[0,1:].values.reshape(28,28),cmap='gray');"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPMZm66c0c5c",
        "colab_type": "code",
        "outputId": "a166b03d-922c-4ffe-dc3e-baa5366ca2e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "plt.imshow(mnist.iloc[100,1:].values.reshape(28,28),cmap='gray');"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x13Y4Pyp00xx",
        "colab_type": "code",
        "outputId": "ef4206c2-32b6-4a5d-cfe8-870e46f74fc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = mnist.iloc[:,1:]\n",
        "y = mnist.iloc[:,0]\n",
        "y.shape, X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2001,), (2001, 784))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7N7b55Le2esZ",
        "colab_type": "code",
        "outputId": "eec4deb3-36c8-4164-e572-ecd892619f39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## keras needs one-hot-encoding\n",
        "y = to_categorical(y)\n",
        "y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2001, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsBAg3ew1YaF",
        "colab_type": "code",
        "outputId": "f01a14d5-2ad3-4d82-c31a-fd716c3ac61d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "model= Sequential()\n",
        "model.add(Dense(50, activation='relu', input_shape = (784,)))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "hist = model.fit(X, y, validation_split=0.3,epochs=15)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1400 samples, validate on 601 samples\n",
            "Epoch 1/15\n",
            "1400/1400 [==============================] - 2s 2ms/step - loss: 11.1666 - acc: 0.2779 - val_loss: 9.4001 - val_acc: 0.3877\n",
            "Epoch 2/15\n",
            "1400/1400 [==============================] - 0s 109us/step - loss: 9.0970 - acc: 0.4143 - val_loss: 8.6738 - val_acc: 0.4443\n",
            "Epoch 3/15\n",
            "1400/1400 [==============================] - 0s 111us/step - loss: 7.6737 - acc: 0.5029 - val_loss: 7.6826 - val_acc: 0.4942\n",
            "Epoch 4/15\n",
            "1400/1400 [==============================] - 0s 116us/step - loss: 6.7832 - acc: 0.5564 - val_loss: 6.9125 - val_acc: 0.5541\n",
            "Epoch 5/15\n",
            "1400/1400 [==============================] - 0s 112us/step - loss: 6.1114 - acc: 0.6057 - val_loss: 6.3175 - val_acc: 0.5824\n",
            "Epoch 6/15\n",
            "1400/1400 [==============================] - 0s 117us/step - loss: 5.6638 - acc: 0.6336 - val_loss: 6.3073 - val_acc: 0.5890\n",
            "Epoch 7/15\n",
            "1400/1400 [==============================] - 0s 112us/step - loss: 5.7971 - acc: 0.6279 - val_loss: 5.8366 - val_acc: 0.6206\n",
            "Epoch 8/15\n",
            "1400/1400 [==============================] - 0s 126us/step - loss: 5.2357 - acc: 0.6636 - val_loss: 5.5520 - val_acc: 0.6389\n",
            "Epoch 9/15\n",
            "1400/1400 [==============================] - 0s 112us/step - loss: 5.3588 - acc: 0.6514 - val_loss: 5.5617 - val_acc: 0.6356\n",
            "Epoch 10/15\n",
            "1400/1400 [==============================] - 0s 108us/step - loss: 4.9302 - acc: 0.6821 - val_loss: 5.0060 - val_acc: 0.6855\n",
            "Epoch 11/15\n",
            "1400/1400 [==============================] - 0s 114us/step - loss: 4.7555 - acc: 0.6943 - val_loss: 5.1197 - val_acc: 0.6722\n",
            "Epoch 12/15\n",
            "1400/1400 [==============================] - 0s 114us/step - loss: 4.4326 - acc: 0.7193 - val_loss: 4.8124 - val_acc: 0.6922\n",
            "Epoch 13/15\n",
            "1400/1400 [==============================] - 0s 115us/step - loss: 4.5218 - acc: 0.7107 - val_loss: 4.6694 - val_acc: 0.6988\n",
            "Epoch 14/15\n",
            "1400/1400 [==============================] - 0s 115us/step - loss: 4.2637 - acc: 0.7314 - val_loss: 4.4353 - val_acc: 0.7105\n",
            "Epoch 15/15\n",
            "1400/1400 [==============================] - 0s 113us/step - loss: 4.5105 - acc: 0.7114 - val_loss: 4.7805 - val_acc: 0.6905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mq-cbrWw2Kod",
        "colab_type": "code",
        "outputId": "99e3a411-9e2d-457c-ec0c-09cefc5cfdd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plt.plot(hist.history['val_loss'], 'r',hist.history['loss'], 'b')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTVZ8AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnRJ_cMW2PhS",
        "colab_type": "code",
        "outputId": "39c04275-f5d8-496d-f508-857d9bf2b6ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plt.plot(hist.history['val_acc'], 'r',hist.history['acc'], 'b')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKRRERKSYQkFERIr9P7WAxfdVyK/+AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa51MN3C2uuo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}