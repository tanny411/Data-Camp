{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "analyzing-police-activity-with-pandas.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "zY-uLGpKpxkJ",
        "yRTeD9V4xTru"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY-uLGpKpxkJ",
        "colab_type": "text"
      },
      "source": [
        "# preparing-the-data-for-analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bp-lF8mrp57u",
        "colab_type": "text"
      },
      "source": [
        "## dropping missing data\n",
        "\n",
        "- `df.isnul()` makes a True/False containing dataframe\n",
        "- `df.isnull().sum()` gives number of missing values in each column\n",
        "- `df.drop('column_name', axis='columns, inplace=True)`\n",
        "- can also pass a list of columns for df.drop()\n",
        "- `df.dropna()` drops all rows that have null in ANY column\n",
        "- `df.dropna(subset=['col1','col2'],inplace=True)` takes into consideration only these columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nymDlpR1sOh7",
        "colab_type": "text"
      },
      "source": [
        "## Using proper data types\n",
        "\n",
        "- df.dtypes\n",
        "- supports bool, int, float, datetime, category(less memory) etc\n",
        "- dtype matters because onit depends what operations we can perform on the series\n",
        "- `df.col.dtype`\n",
        "- `df['col'] = df.col.astype('float')` #to change the dtype\n",
        "- 'HAVE' to use bracket notation on the ;eft side of the assignment statement to create a new series of overwrite an existing one"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEbmm8IqvaaZ",
        "colab_type": "text"
      },
      "source": [
        "## Creating a datetime index\n",
        "\n",
        "- concat date and time column by `combined = df.datecol.str.cat(df.timecol, sep=' )`\n",
        "- df['datetime'] = pd.to_datetime(combined)\n",
        "- set as index : `df.set_index('datetime', inplace=True)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRTeD9V4xTru",
        "colab_type": "text"
      },
      "source": [
        "# exploring-the-relationship-between-gender-and-policing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJL_ioutxUxh",
        "colab_type": "text"
      },
      "source": [
        "## Exploring realtionship\n",
        "\n",
        "- `df.col.value_counts()` on categorical data to see the different unnique kinds of data in that row\n",
        "- `df.col.value_counts(normalize=True)` to output in proportions (value_counts/total) i.e in percents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWa_lIqexUvV",
        "colab_type": "text"
      },
      "source": [
        "## Filtering\n",
        "\n",
        "- `df[(df.col=='A') & (df.col2=='B')]`\n",
        "- each condition must be surrounded by ()\n",
        "\n",
        "## Groupby\n",
        "- mean of a boolean series = percentage of True values\n",
        "- `df.groupby('col').col2.mean()`\n",
        "- `df.groupby(['col1','col3']).col2.mean()`\n",
        "\n",
        "## Contains\n",
        "- value_counts excludes NaNs so to see it do this: `value_counts(dropna=False)`\n",
        "- `df.col.str.contains('somestring',na=False)` na=False tells yo return false for null values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPEQtsUr482b",
        "colab_type": "text"
      },
      "source": [
        "# visual-exploratory-data-analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkZNRIhf49zt",
        "colab_type": "text"
      },
      "source": [
        "## datetime\n",
        "- df.datecol.dt.month : to access the month as integers\n",
        "- for an index of datetime type: df.index.month\n",
        "- groupby month?? : df.groupby(df.index.month).col.mean()\n",
        "- df.col.dt.hour\n",
        "  - 0 = midnight\n",
        "  - 12 = noon\n",
        "  - 23 = 11 PM\n",
        "\n",
        "## resample and subplot\n",
        "- groupby month can also be done by resampling. here index has to be the datetime type though.\n",
        "- df.col.resample('M').mean()\n",
        "- df.plot(subplots=True)\n",
        "\n",
        "## types of plots\n",
        "- crs = df.crosstab(df.col1, df.col2) where col1,2 are categorical. this returns a dataframe of frequency.\n",
        "- crs.plot(kind='bar') for categorical data\n",
        "- crs.plot(kind='bar', stacked=True), lets you see the totals\n",
        "\n",
        "## mapping\n",
        "- mapping = {'up'=True, 'down':False}; df.col.map(mapping)\n",
        "- kind='barh' in plotting\n",
        "- .sort_values() and then plot for better undestanding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqmY8cN1BKYH",
        "colab_type": "text"
      },
      "source": [
        "# analyzing-the-effect-of-weather-on-policing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3zr7v6aBOmU",
        "colab_type": "text"
      },
      "source": [
        "## Exploring Dataset\n",
        "- make sure data is trustworthy and devoid of outliers by\n",
        "  - df.describe()\n",
        "  - df.plot(kind='box')\n",
        "- take diff of maxTemp and mintemp values and get a histofram to check no values are below zero, essentially `maxTemp<minTemp` which wouldnt make sense!\n",
        "  - weather['TDIFF'].plot(kind='hist', bins=20)\n",
        "  - if it is a normal distribution, its natural, and so probably correct\n",
        "\n",
        "##  cats and ordering\n",
        "- `df.sum()` column wise add\n",
        "- `df.sum(axis='columns')`\n",
        "- categorization reduces memory usage\n",
        "- see mem use by: `df.col.memort_usage(deep=True)`\n",
        "- categories can also be ordered: `df.col.astype('category',ordered=True, categories=['short','medium','long'])`\n",
        "- because of ordering you can now use comparison operators with this column. e.g df.col>'short'\n",
        "\n",
        "## reset\n",
        "- .reset_index() will make it range index\n",
        "\n",
        "## multi-index series\n",
        "- .unstack on a multi-index series(maybe created by groupby on multiple columns), is a dataframe\n",
        "- pivot_table can achieve the same result as groupby+unstack in the previous case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RbqaE-BN-_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the output of the groupby operation from the last exercise\n",
        "arrest_rate = ri_weather.groupby(['violation', 'rating']).is_arrested.mean()\n",
        "\n",
        "# Print the 'arrest_rate' Series\n",
        "print(arrest_rate)\n",
        "\n",
        "# Print the arrest rate for moving violations in bad weather\n",
        "print(arrest_rate.loc['Moving violation','bad'])\n",
        "\n",
        "# Print the arrest rates for speeding violations in all three weather conditions\n",
        "print(arrest_rate.loc['Speeding'])\n",
        "\n",
        "# Unstack the 'arrest_rate' Series into a DataFrame\n",
        "print(arrest_rate.unstack())\n",
        "\n",
        "# Create the same DataFrame using a pivot table\n",
        "print(ri_weather.pivot_table(index='violation', columns='rating', values='is_arrested'))\n",
        "## output is supposed to be same as above"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}