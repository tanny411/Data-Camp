{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "importing-data-in-python-part-1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "AlzffnfGYThf",
        "PmFf65Zfejtp",
        "Wsze-UbzgVmm",
        "NubQrwxThY0K",
        "3WElNFN2nXI5",
        "cC5nuSaXbOfJ",
        "zI_28NFtZA4K",
        "yIxoOSxjaoLF",
        "6x2pl-a0fL1n"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlzffnfGYThf",
        "colab_type": "text"
      },
      "source": [
        "# From File\n",
        "\n",
        "1. file = open(filename, mode='r')\n",
        "    text = file.read()\n",
        "    file.close()\n",
        "    \n",
        "2. with open(filename,mode='r'):\n",
        "        '''\n",
        "        code within the block\n",
        "        '''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT40JjnWeIpJ",
        "colab_type": "text"
      },
      "source": [
        "--> reading Emne"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qe6V19SWeBt",
        "colab_type": "code",
        "outputId": "6b85a16a-d4df-4049-fdfa-df3f68083188",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "file = open('test.txt','r')\n",
        "text = file.read()\n",
        "print(text[:50])\n",
        "#test if file is closed\n",
        "print(file.closed)\n",
        "file.close()\n",
        "print(file.closed)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bangladesh, officially the People's Republic of Ba\n",
            "False\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpkiGjg2eF3w",
        "colab_type": "text"
      },
      "source": [
        "-->  reading line by line"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5-6LHJDd0YU",
        "colab_type": "code",
        "outputId": "9eb4c889-cfc8-46e6-ea0f-665b082152ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "with open('test.txt','r') as file:\n",
        "    print(file.readline())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bangladesh, officially the People's Republic of Bangladesh (গণপ্রজাতন্ত্রী বাংলাদেশ Gônoprojatontri Bangladesh), is a country in South Asia. It shares land borders with India and Myanmar. Bangladesh is the 92nd-largest sovereign state in the world, with an area of 147,570 square kilometres (56,980 sq mi). It is also the world's 8th-most populous country, as well as one of its most densely-populated. Dhaka is its capital and largest city, and is also the economic, political and the cultural center of Bangladesh, followed by Chittagong, which has the country's largest port. Bangladesh forms the largest and eastern part of the Bengal region.[11] The country's geography is dominated by the Bengal delta, the largest delta in the world. The country has many rivers and 8,046 km (5,000 mi) of inland waterways. Highlands with evergreen forests are found in the northeastern and southeastern regions of the country. The country also has the longest sea beach and the largest mangrove forest in the world. The country's biodiversity includes a vast array of plants and wildlife, including the endangered Bengal tiger, the national animal.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmFf65Zfejtp",
        "colab_type": "text"
      },
      "source": [
        "# Flat Files: csv,txt\n",
        "\n",
        "- flat files are basic text files, that contain records of tabular data\n",
        "- can contain headers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wsze-UbzgVmm",
        "colab_type": "text"
      },
      "source": [
        "### Why we like flat files and the Zen of Python\n",
        "In PythonLand, there are currently hundreds of Python Enhancement Proposals, commonly referred to as PEPs. PEP8, for example, is a standard style guide for Python, written by our sensei Guido van Rossum himself. It is the basis for how we here at DataCamp ask our instructors to style their code. Another one of my favorites is PEP20, commonly called the Zen of Python. Its abstract is as follows:\n",
        "\n",
        "    '''\n",
        "    Long time Pythoneer Tim Peters succinctly channels the BDFL's guiding principles for Python's design into 20 aphorisms, only 19 of which have been written down.\n",
        "    '''\n",
        "\n",
        "If you don't know what the acronym BDFL stands for, I suggest that you look here. You can print the Zen of Python in your shell by typing import this into it! You're going to do this now and the 5th aphorism (line) will say something of particular interest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TKYW8z_edmR",
        "colab_type": "code",
        "outputId": "493c73e7-c679-4f77-d7df-a49c8151e2c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "import this"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Zen of Python, by Tim Peters\n",
            "\n",
            "Beautiful is better than ugly.\n",
            "Explicit is better than implicit.\n",
            "Simple is better than complex.\n",
            "Complex is better than complicated.\n",
            "Flat is better than nested.\n",
            "Sparse is better than dense.\n",
            "Readability counts.\n",
            "Special cases aren't special enough to break the rules.\n",
            "Although practicality beats purity.\n",
            "Errors should never pass silently.\n",
            "Unless explicitly silenced.\n",
            "In the face of ambiguity, refuse the temptation to guess.\n",
            "There should be one-- and preferably only one --obvious way to do it.\n",
            "Although that way may not be obvious at first unless you're Dutch.\n",
            "Now is better than never.\n",
            "Although never is often better than *right* now.\n",
            "If the implementation is hard to explain, it's a bad idea.\n",
            "If the implementation is easy to explain, it may be a good idea.\n",
            "Namespaces are one honking great idea -- let's do more of those!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NubQrwxThY0K",
        "colab_type": "text"
      },
      "source": [
        "### numerical data in '' numpy ''\n",
        "-- fyi : can handle only one datatype"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLqVveswiDBT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXxCaFvtgzdn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = np.loadtxt('test.txt',delimiter=' ', skiprows=0, usecols=[0,2] , dtype=str) \n",
        "#delimiter=' ', skiprows=0, usecols=[0,2] , dtype=str -----> are optional"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHZOao2siAkb",
        "colab_type": "code",
        "outputId": "81c30283-432d-41eb-d9e0-31ca4eea324b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['Bangladesh,', 'the'],\n",
              "       ['In', 'ancient'],\n",
              "       ['Islam', 'introduced'],\n",
              "       ['Bangladeshis', 'people']], dtype='<U12')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXagGXnvk5kQ",
        "colab_type": "text"
      },
      "source": [
        "Much of the time you will need to import datasets which have different datatypes in different columns; one column may contain strings and another floats, for example. The function np.loadtxt() will freak at this. There is another function, **np.genfromtxt()**, which can handle such structures. If we pass dtype=None to it, it will figure out what types each column should be.\n",
        "\n",
        "    '''\n",
        "        data = np.genfromtxt('titanic.csv', delimiter=',', names=True, dtype=None)\n",
        "    '''\n",
        "Here, the first argument is the filename, the second specifies the delimiter , and the third argument names tells us there is a header. Because the data are of different types, data is an object called a structured array. Because numpy arrays have to contain elements that are all the same type, the structured array solves this by being a 1D array, where each element of the array is a row of the flat file imported. You can test this by checking out the array's shape in the shell by executing np.shape(data).\n",
        "\n",
        "Accessing rows and columns of structured arrays is super-intuitive: to get the ith row, merely execute data[i] and to get the column with name 'Fare', execute data['Fare']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93F1go-Emvc9",
        "colab_type": "text"
      },
      "source": [
        "You have just used np.genfromtxt() to import data containing mixed datatypes. There is also another function **np.recfromcsv()** that behaves similarly to np.genfromtxt(), except that its default dtype is None. In this exercise, you'll practice using this to achieve the same result.\n",
        "\n",
        "It has the defaults delimiter=',' and names=True in addition to dtype=None!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WElNFN2nXI5",
        "colab_type": "text"
      },
      "source": [
        "### In Pandas\n",
        "\n",
        "- 2D labeled datastructures\n",
        "- columns of potentially different datastructures\n",
        "- manipulate , slice, reshape, groupby, join\n",
        "- perform _statistics_\n",
        "\n",
        "-  the DataFrame object in pandas is a more appropriate structure in which to store such data and, thankfully, we can easily import files of mixed data types as DataFrames using the pandas functions read_csv() and read_table()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_yuRgAriIeK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(filename) #header=None,nrows=5\n",
        "\n",
        "array_ = df.values ##humm!!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3GzsJpqvRWO",
        "colab_type": "text"
      },
      "source": [
        "In the next example:\n",
        "\n",
        "- contains comments after the character '#'\n",
        "- is tab-delimited."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewwEd5JsvlRt",
        "colab_type": "text"
      },
      "source": [
        "Complete the sep (the pandas version of delim), comment and na_values arguments of pd.read_csv(). comment takes characters that comments occur after in the file, which in this case is '#'. na_values takes a list of strings to recognize as NA/NaN, in this case the string 'Nothing'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0e1HeKUvVA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(file, sep='\\t', comment='#', na_values='Nothing')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cgg4Ifmvm2r",
        "colab_type": "text"
      },
      "source": [
        "# Other Files\n",
        "(.xlsx is not a flat because it is a spreadsheet consisting of many sheets, not a single table.)\n",
        " - excel, matlab, sas, stata , hd5\n",
        " \n",
        " \n",
        " ### Pickled file\n",
        " - native to python\n",
        " - mode='rb' = read only + binary\n",
        " - pickle files are stored in binary format, and any python stuff can be stored with it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrZAAqP4aq5O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "90642983-b8a2-4b3e-dd3e-dcd6313bbc33"
      },
      "source": [
        "#accessing current directory\n",
        "import os\n",
        "wd = os.getcwd()\n",
        "os.listdir(wd)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'sample_data']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cC5nuSaXbOfJ",
        "colab_type": "text"
      },
      "source": [
        "### Pickling\n",
        "\n",
        "There are a number of datatypes that cannot be saved easily to flat files, such as lists and dictionaries. If you want your files to be human readable, you may want to save them as text files in a clever manner. JSONs, which you will see in a later chapter, are appropriate for Python dictionaries.\n",
        "\n",
        "However, if you merely want to be able to import them into Python, you can serialize them. All this means is converting the object into a sequence of bytes, or a bytestream."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ktijmm20bi-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import pickle package\n",
        "import pickle\n",
        "\n",
        "# Open pickle file and load data: d\n",
        "with open('data.pkl', 'rb') as file:\n",
        "    d = pickle.load(file)\n",
        "\n",
        "# Print d\n",
        "print(d)\n",
        "\n",
        "# Print datatype of d\n",
        "print(type(d))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI_28NFtZA4K",
        "colab_type": "text"
      },
      "source": [
        "### Excel sheets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIiXmBLJXyEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.ExcelFile(filename)\n",
        "\n",
        "print(data.sheet_names)\n",
        "\n",
        "df1 = data.parse(sheet1) #sheet name as a string\n",
        "\n",
        "df2 = data.parse(0) #sheet index as a float"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcOOZaMEcqiH",
        "colab_type": "text"
      },
      "source": [
        "- Parse the first sheet by index. In doing so, skip the first row of data and name the columns 'Country' and 'AAM due to War (2002)' using the argument names. The values passed to skiprows and names all need to be of type list.\n",
        "\n",
        "- Parse the second sheet by index. In doing so, parse only the first column with the usecols parameter, skip the first row and rename the column 'Country'. The argument passed to usecols also needs to be of type list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRHgLLOAc4yU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parse the first sheet and rename the columns: df1\n",
        "df1 = xls.parse(0 , skiprows=[0], names=['Country','AAM due to War (2002)'])\n",
        "\n",
        "# Print the head of the DataFrame df1\n",
        "print(df1.head())\n",
        "\n",
        "# Parse the first column of the second sheet and rename the column: df2\n",
        "df2 = xls.parse(1, usecols=[0], skiprows=[0], names=['Country'])\n",
        "\n",
        "# Print the head of the DataFrame df2\n",
        "print(df2.head())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIxoOSxjaoLF",
        "colab_type": "text"
      },
      "source": [
        "### SAS/Stata files\n",
        "\n",
        "1. SAS - statistical analysis system : standard file type for statistical analysis\n",
        "    - file extension = .sas7bdat , .sas7bcat\n",
        "    - with : from sas7bdat import SAS7BDAT\n",
        "2. stata file :\n",
        "    - extension = .dta\n",
        "    - with pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7j92ogKldV1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sas7bdat import SAS7BDAT\n",
        "\n",
        "with SAS7BDAT('sales.sas7bdat') as file:\n",
        "    df_sas = file.to_data_frame()\n",
        "\n",
        "print(df_sas.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HabW895bfIFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load Stata file into a pandas DataFrame: df\n",
        "df = pd.read_stata('disarea.dta')\n",
        "\n",
        "print(df.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x2pl-a0fL1n",
        "colab_type": "text"
      },
      "source": [
        "### HDF5 file\n",
        "\n",
        "- heirarchical data format version 5\n",
        "- large quantities of numerical data\n",
        "- 100s of GB or even TBs\n",
        "- hdf5 can scale upto exabytes\n",
        "- can explore the heirarchy of the file with .keys()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qajtoj8bfNPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import packages\n",
        "import numpy as np\n",
        "import h5py\n",
        "\n",
        "# Assign filename: file\n",
        "file = 'LIGO_data.hdf5'\n",
        "\n",
        "# Load file: data\n",
        "data = h5py.File(file, 'r')\n",
        "\n",
        "# Print the datatype of the loaded file\n",
        "print(type(data))\n",
        "\n",
        "# Print the keys of the file\n",
        "for key in data.keys():\n",
        "    print(key)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXGdMxOWgjsB",
        "colab_type": "text"
      },
      "source": [
        "output: \n",
        "\n",
        "<class 'h5py._hl.files.File'>\n",
        "   \n",
        "   meta\n",
        "   \n",
        "   quality\n",
        "   \n",
        "   strain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9sgLmA5hckw",
        "colab_type": "text"
      },
      "source": [
        "### Matlab files\n",
        "\n",
        "- .mat files\n",
        "-  scipy.io.savemat()\n",
        "- scipy.io.loadmat()\n",
        "- loaded as dicts\n",
        "- keys = variables, values = objects assigned to the variables\n",
        "- .mat contains only the list of vaiables from the matlab worspace"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLX1qMwIhd7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import package\n",
        "import scipy.io\n",
        "\n",
        "# Load MATLAB file: mat\n",
        "mat = scipy.io.loadmat('albeck_gene_expression.mat')\n",
        "\n",
        "# Print the datatype type of mat\n",
        "print(type(mat))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gz6-IScUi6R7",
        "colab_type": "text"
      },
      "source": [
        "Use the method .keys() on the dictionary mat to print the keys. Most of these keys (in fact the ones that do NOT begin and end with '__') are variables from the corresponding MATLAB environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Srusn-pujs9b",
        "colab_type": "text"
      },
      "source": [
        "# Relational Database\n",
        "\n",
        "- postgreSQL\n",
        "- MySQL\n",
        "- SQLite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANprydJ1lBct",
        "colab_type": "text"
      },
      "source": [
        "### creating a database engine in python\n",
        "\n",
        "Here, you're going to fire up your very first SQL engine. You'll create an engine to connect to the SQLite database 'Chinook.sqlite', which is in your working directory. Remember that to create an engine to connect to 'Northwind.sqlite', Hugo executed the command\n",
        "\n",
        "    '''\n",
        "    engine = create_engine('sqlite:///Northwind.sqlite')\n",
        "    '''\n",
        "Here, 'sqlite:///Northwind.sqlite' is called the connection string to the SQLite database Northwind.sqlite. A little bit of background on the [Chinook database](https://github.com/lerocha/chinook-database): the Chinook database contains information about a semi-fictional digital media store in which media data is real and customer, employee and sales data has been manually created."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SDBWj31juhV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import necessary module\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "# Create engine: engine\n",
        "engine = create_engine('sqlite:///Chinook.sqlite')\n",
        "\n",
        "# Save the table names to a list: table_names\n",
        "table_names = engine.table_names()\n",
        "\n",
        "# Print the table names to the shell\n",
        "print(table_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ek8r0vypmiwA",
        "colab_type": "text"
      },
      "source": [
        "['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEdY7A0rmoYz",
        "colab_type": "text"
      },
      "source": [
        "### Query the database\n",
        "\n",
        "- fetchall/featchmany(size=3) - > pd.DataFrame(rs.fetchall())\n",
        "- with context manager as engine.connect() as con\n",
        "- w/o context, con=engine.connect() ; con.execute('sql squry here') --> dont forget to close the connection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddrpFvZImD-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import packages\n",
        "from sqlalchemy import create_engine\n",
        "import pandas as pd\n",
        "\n",
        "# Create engine: engine\n",
        "engine = create_engine('sqlite:///Chinook.sqlite')\n",
        "\n",
        "# Open engine connection: con\n",
        "con = engine.connect()\n",
        "\n",
        "# Perform query: rs\n",
        "rs = con.execute('SELECT * from Album')\n",
        "\n",
        "# Save results of the query to DataFrame: df\n",
        "df = pd.DataFrame(rs.fetchall())\n",
        "\n",
        "# Close connection\n",
        "con.close()\n",
        "\n",
        "# Print head of DataFrame df\n",
        "print(df.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU3pVxFRokmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Open engine in context manager\n",
        "# Perform query and save results to DataFrame: df\n",
        "with engine.connect() as con:\n",
        "    rs = con.execute('SELECT LastName, Title FROM Employee')\n",
        "    df = pd.DataFrame(rs.fetchmany(size=3))\n",
        "    df.columns = rs.keys()\n",
        "\n",
        "# Print the length of the DataFrame df\n",
        "print(len(df))\n",
        "\n",
        "# Print the head of the DataFrame df\n",
        "print(df.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksQERU2RpusA",
        "colab_type": "text"
      },
      "source": [
        "### Querying with Pandas\n",
        "- the power of pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mxwr_S3pwTY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import packages\n",
        "from sqlalchemy import create_engine\n",
        "import pandas as pd\n",
        "\n",
        "# Create engine: engine\n",
        "engine = create_engine('sqlite:///Chinook.sqlite')\n",
        "\n",
        "# Execute query and store records in DataFrame: df\n",
        "df = pd.read_sql_query('SELECT * FROM Album', engine)\n",
        "\n",
        "# Print head of DataFrame\n",
        "print(df.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayQxdLat4Byw",
        "colab_type": "text"
      },
      "source": [
        "### Advanced Querying : Exploiting the table relationaships"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQi-9wMM4G3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Here, you'll perform your first INNER JOIN! You'll be working with your favourite SQLite database, \n",
        "Chinook.sqlite. For each record in the Album table, you'll extract the Title along with the Name of the Artist. \n",
        "The latter will come from the Artist table and so you will need to INNER JOIN these two tables on the ArtistID column of both.\n",
        "'''\n",
        "\n",
        "# Open engine in context manager\n",
        "# Perform query and save results to DataFrame: df\n",
        "with engine.connect() as con:\n",
        "    rs = con.execute('SELECT Title,Name FROM Album INNER JOIN Artist ON Album.ArtistID=Artist.ArtistID')\n",
        "    df = pd.DataFrame(rs.fetchall())\n",
        "    df.columns=rs.keys()\n",
        "\n",
        "# Print head of DataFrame df\n",
        "print(df.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZ6aF95f5udP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Execute query and store records in DataFrame: df\n",
        "df = pd.read_sql_query('SELECT * FROM PlaylistTrack INNER JOIN Track on PlaylistTrack.TrackId = Track.TrackId WHERE Milliseconds < 250000',engine)\n",
        "\n",
        "# Print head of DataFrame\n",
        "print(df.head())"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}